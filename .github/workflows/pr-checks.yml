name: PR Checks

on:
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'PR number'
        required: false
        type: string
      pr_head_sha:
        description: 'PR head SHA'
        required: false
        type: string

jobs:
  test-and-coverage:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov
        pip install pyyaml jsonschema click openpyxl
        
        # Install project dependencies
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        elif [ -f requirements-dev.txt ]; then
          pip install -r requirements-dev.txt
        fi
        
        # Install the project itself
        pip install -e .

    - name: Install cdlreq
      run: |
        # Install cdlreq for coverage verification
        export PYTHONPATH="/tmp/cdlreq:$PYTHONPATH"
        
        if git clone https://github.com/SeanHgh/cdlreq.git /tmp/cdlreq; then
          echo "Successfully cloned cdlreq"
          cd /tmp/cdlreq
          
          # Try pip install first
          if pip install -e . 2>/dev/null; then
            echo "Successfully installed cdlreq with pip"
          else
            echo "Pip install failed, using manual setup"
            export PYTHONPATH="/tmp/cdlreq:$PYTHONPATH"
          fi
        else
          echo "Failed to clone cdlreq repository"
          exit 1
        fi

    - name: Validate specification unit tests
      id: validate_specs
      run: |
        echo "Validating specification unit test paths..."
        
        # Set up Python path for cdlreq
        export PYTHONPATH="/tmp/cdlreq:$PYTHONPATH"
        
        # Run cdlreq validation for specifications
        if python -c "import cdlreq" 2>/dev/null; then
          echo "Using cdlreq Python module for specification validation"
          
          # Validate all specifications have valid unit test paths
          if python -c "
import sys
sys.path.insert(0, '/tmp/cdlreq')
from cdlreq.validation import validate_specifications
result = validate_specifications('.')
sys.exit(0 if result else 1)
" > spec_validation_output.txt 2>&1; then
            SPEC_VALIDATION_EXIT_CODE=0
            echo "‚úÖ All specification unit test paths are valid"
          else
            SPEC_VALIDATION_EXIT_CODE=1
            echo "‚ùå Some specification unit test paths are invalid"
          fi
          
          echo "=== SPECIFICATION VALIDATION OUTPUT ==="
          cat spec_validation_output.txt
          echo "======================================="
          
          echo "spec_validation_exit_code=$SPEC_VALIDATION_EXIT_CODE" >> $GITHUB_OUTPUT
          
          if [ $SPEC_VALIDATION_EXIT_CODE -ne 0 ]; then
            echo "üö´ Blocking PR merge due to invalid specification unit test paths"
            exit 1
          fi
        else
          echo "‚ö†Ô∏è Could not import cdlreq for specification validation"
          echo "spec_validation_exit_code=0" >> $GITHUB_OUTPUT
        fi

    - name: Run pytest and save output
      id: pytest
      run: |
        echo "Running pytest tests..."
        
        # Run pytest with coverage and save output to file
        pytest tests/ --tb=short --no-header -v > pytest_output.txt 2>&1
        PYTEST_EXIT_CODE=$?
        
        echo "Pytest completed with exit code: $PYTEST_EXIT_CODE"
        echo "pytest_exit_code=$PYTEST_EXIT_CODE" >> $GITHUB_OUTPUT
        
        # Display the output
        echo "=== PYTEST OUTPUT ==="
        cat pytest_output.txt
        echo "===================="
        
        # Don't exit here - let coverage check decide final result
        echo "Pytest output saved to pytest_output.txt"

    - name: Verify test coverage with cdlreq
      id: coverage
      run: |
        echo "Verifying test coverage with cdlreq..."
        
        # Set up Python path for cdlreq
        export PYTHONPATH="/tmp/cdlreq:$PYTHONPATH"
        
        # Run cdlreq coverage check
        if python -c "import cdlreq" 2>/dev/null; then
          echo "Using cdlreq Python module for coverage verification"
          
          # Try to run coverage check with pytest output file
          if python -c "from cdlreq.cli.commands import cli; cli(['coverage', 'pytest_output.txt', '--directory', '.'])" > coverage_output.txt 2>&1; then
            COVERAGE_EXIT_CODE=0
          else
            COVERAGE_EXIT_CODE=1
          fi
          
          echo "Coverage check completed with exit code: $COVERAGE_EXIT_CODE"
          echo "coverage_exit_code=$COVERAGE_EXIT_CODE" >> $GITHUB_OUTPUT
          
          # Display coverage output
          echo "=== COVERAGE OUTPUT ==="
          cat coverage_output.txt
          echo "======================="
          
        else
          echo "Error: Could not import cdlreq for coverage verification"
          echo "coverage_exit_code=1" >> $GITHUB_OUTPUT
          COVERAGE_EXIT_CODE=1
        fi
        
        # Check if coverage verification passed
        if [ $COVERAGE_EXIT_CODE -ne 0 ]; then
          echo "‚ùå Coverage verification failed"
          echo "Some specifications have untested unit test paths"
          exit 1
        else
          echo "‚úÖ Coverage verification passed"
        fi

    - name: Check final results
      run: |
        SPEC_VALIDATION_CODE=${{ steps.validate_specs.outputs.spec_validation_exit_code }}
        PYTEST_CODE=${{ steps.pytest.outputs.pytest_exit_code }}
        COVERAGE_CODE=${{ steps.coverage.outputs.coverage_exit_code }}
        
        echo "=== FINAL RESULTS ==="
        echo "Specification validation exit code: $SPEC_VALIDATION_CODE"
        echo "Pytest exit code: $PYTEST_CODE"
        echo "Coverage exit code: $COVERAGE_CODE"
        
        if [ "$SPEC_VALIDATION_CODE" -ne 0 ]; then
          echo "‚ùå Specification unit test validation failed"
          FINAL_RESULT=1
        elif [ "$PYTEST_CODE" -ne 0 ]; then
          echo "‚ùå Pytest tests failed"
          FINAL_RESULT=1
        elif [ "$COVERAGE_CODE" -ne 0 ]; then
          echo "‚ùå Coverage verification failed"
          FINAL_RESULT=1
        else
          echo "‚úÖ All checks passed"
          FINAL_RESULT=0
        fi
        
        echo "===================="
        
        if [ $FINAL_RESULT -ne 0 ]; then
          echo "üö´ PR checks failed - blocking merge"
          exit 1
        else
          echo "üéâ PR checks passed - ready to merge"
        fi

    - name: Upload test outputs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-outputs
        path: |
          spec_validation_output.txt
          pytest_output.txt
          coverage_output.txt
        retention-days: 30

    - name: Comment on PR with results
      if: always() && github.event.inputs.pr_number
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          const specValidationCode = '${{ steps.validate_specs.outputs.spec_validation_exit_code }}';
          const pytestCode = '${{ steps.pytest.outputs.pytest_exit_code }}';
          const coverageCode = '${{ steps.coverage.outputs.coverage_exit_code }}';
          
          let specValidationOutput = '';
          let pytestOutput = '';
          let coverageOutput = '';
          
          try {
            specValidationOutput = fs.readFileSync('spec_validation_output.txt', 'utf8');
          } catch (e) {
            specValidationOutput = 'No specification validation output available';
          }
          
          try {
            pytestOutput = fs.readFileSync('pytest_output.txt', 'utf8');
          } catch (e) {
            pytestOutput = 'No pytest output available';
          }
          
          try {
            coverageOutput = fs.readFileSync('coverage_output.txt', 'utf8');
          } catch (e) {
            coverageOutput = 'No coverage output available';
          }
          
          const specValidationStatus = specValidationCode === '0' ? '‚úÖ PASSED' : '‚ùå FAILED';
          const pytestStatus = pytestCode === '0' ? '‚úÖ PASSED' : '‚ùå FAILED';
          const coverageStatus = coverageCode === '0' ? '‚úÖ PASSED' : '‚ùå FAILED';
          const overallStatus = (specValidationCode === '0' && pytestCode === '0' && coverageCode === '0') ? 'üéâ READY TO MERGE' : 'üö´ MERGE BLOCKED';
          
          const body = "## üîç PR Checks Results\n\n" + overallStatus + 
            "\n\n### üìä Test Results Summary:\n" +
            "- **Specification Validation**: " + specValidationStatus + "\n" +
            "- **Pytest Tests**: " + pytestStatus + "\n" +
            "- **Coverage Verification**: " + coverageStatus + "\n\n" +
            "### üìã Specification Validation:\n<details>\n<summary>Click to expand specification validation results</summary>\n\n```\n" +
            specValidationOutput.slice(0, 2000) + (specValidationOutput.length > 2000 ? '\n... (output truncated)' : '') +
            "\n```\n</details>\n\n" +
            "### üß™ Pytest Output:\n<details>\n<summary>Click to expand pytest results</summary>\n\n```\n" +
            pytestOutput.slice(0, 2000) + (pytestOutput.length > 2000 ? '\n... (output truncated)' : '') +
            "\n```\n</details>\n\n" +
            "### üìà Coverage Verification:\n<details>\n<summary>Click to expand coverage results</summary>\n\n```\n" +
            coverageOutput.slice(0, 2000) + (coverageOutput.length > 2000 ? '\n... (output truncated)' : '') +
            "\n```\n</details>\n\n---\n" +
            (overallStatus === 'üö´ MERGE BLOCKED' ? 
              '**‚ùå This PR cannot be merged until all checks pass (specification validation, tests, and coverage).**' : 
              '**‚úÖ This PR has passed all checks and is ready to merge.**') +
            "\n\n*Automated PR checks with specification validation, pytest testing, and cdlreq coverage verification*";
          
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: '${{ github.event.inputs.pr_number }}',
            body: body
          });
